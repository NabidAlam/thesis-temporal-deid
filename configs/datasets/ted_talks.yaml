dataset:
  name: "ted_talks"
  type: "presentation"
  description: "TED talk videos optimized for speaker-centric de-identification with controlled environments"
  
  # Core pipeline parameters
  processing:
    max_frames: null  # null = process all frames
    temporal_window_size: 10  # Increased from 7 for better temporal consistency
    confidence_threshold: 0.55  # Lowered from 0.6 for more robust detection in stage lighting
    mask_quality_threshold: 0.45  # Lowered from 0.5 for better stage lighting adaptation
    mask_consolidation: true  # Merge similar masks for cleaner output
    temporal_smoothing: true  # Smooth masks across frames for consistency
    frame_skip_interval: 1  # Process every frame for maximum quality
    
  # Model-specific configurations
  tsp_sam:
    input_sizes: [352, 320, 256]  # Paper-validated square dimensions
    temporal_processing: true
    fallback_to_single_frame: true
    checkpoint_path: "tsp_sam_official/model_checkpoint/pvt_v2_b5.pth"
    fallback_checkpoint: "tsp_sam_official/model_checkpoint/best_checkpoint.pth"
    adaptive_threshold: true  # Enable dynamic threshold adjustment
    temporal_consistency_weight: 0.8  # Weight for temporal consistency
    mask_refinement_iterations: 2  # Additional refinement passes for quality
    
  samurai:
    person_detection: true
    confidence_threshold: 0.35  # Lowered from 0.4 for more robust detection
    max_persons: 20  # Reduced from 30 (TED talks rarely have >5 people)
    checkpoint_path: "samurai_official/sam2/checkpoints/sam2.1_hiera_large.pt"
    enable_caching: true  # Enable frame caching
    person_tracking: true  # Enable temporal person tracking
    background_aware_detection: true  # Better for stage environments
    temporal_consistency: true  # Maintain consistency across frames
    
  maskanyone:
    deidentification_strength: "strong"  # Strong de-identification for public figures
    preserve_identity: false
    checkpoint_path: "maskanyone/worker/masking/mask_renderer.py"
    temporal_mask_consistency: true  # Ensure consistent de-identification across frames
    
  # TED-specific optimizations
  ted_optimizations:
    stage_lighting_adaptation: true
    speaker_prioritization: true
    background_subtraction: true
    motion_sensitivity: "high"
    professional_setting: true
    controlled_environment: true
    speaker_tracking: true  # Track main speaker across frames
    stage_boundary_detection: true  # Better stage area detection
    lighting_compensation: true  # Compensate for stage lighting changes
    audience_exclusion: true  # Focus on speaker, exclude audience
    presentation_mode: true  # Optimize for presentation-style videos
    
  # Output settings
  output:
    save_original_frames: true
    save_deidentified_frames: true
    save_masks: true  # Changed to true for analysis and debugging
    save_performance_report: true
    frame_format: "jpg"
    quality: 95
    save_temporal_analysis: true  # Save temporal consistency metrics
    save_mask_evolution: true  # Save how masks evolve across frames
    save_processing_metadata: true  # Save detailed processing information
    
  # Performance settings
  performance:
    enable_cuda: true
    batch_size: 2  # Increased from 1 for better GPU utilization
    memory_efficient: true
    debug_mode: false
    parallel_processing: true  # Enable if memory allows
    gpu_memory_optimization: true  # Optimize GPU memory usage
    frame_processing_optimization: true  # Optimize frame processing pipeline
    
  # Cache settings
  cache:
    enable_frame_cache: true
    max_cache_size: 1000  # Increased from 500 for better hit rates
    cache_ttl: 3600  # Increased from 1800 (1 hour) for longer retention
    adaptive_cache_size: true  # Dynamically adjust cache size
    temporal_cache_window: 10  # Cache frames within temporal window
    mask_cache_enabled: true  # Cache generated masks
    temporal_consistency_cache: true  # Cache temporal consistency data
    
  # Fallback strategies
  fallback:
    tsp_sam_fallback: "single_frame"
    samurai_fallback: "lower_threshold"
    maskanyone_fallback: "strong_deidentification"
    temporal_fallback: "frame_interpolation"  # Interpolate masks if temporal processing fails
    quality_fallback: "adaptive_threshold"  # Adapt thresholds based on frame quality
    
  # Quality assurance
  quality_assurance:
    mask_consistency_check: true  # Verify mask consistency across frames
    temporal_smoothness: true  # Ensure smooth temporal transitions
    deidentification_verification: true  # Verify de-identification effectiveness
    performance_monitoring: true  # Monitor processing performance
    error_recovery: true  # Enable error recovery mechanisms
